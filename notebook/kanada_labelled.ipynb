{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python3 /home/saurabh/transliterated/translate_copy.py \\\n",
    "#     --root_dir=/home/saurabh/dataset/openslr/kanada/labelled \\\n",
    "#     --dst_folder=/home/saurabh/manifest/new/kanada_labelled \\\n",
    "#     --valid_percent=0.2 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOkenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #wpe - working on\n",
    "# ! python3 /home/saurabh/nemo/NeMo/scripts/tokenizers/process_asr_text_tokenizer.py \\\n",
    "#     --data_file=/home/saurabh/dataset/corpus_data_for_tokenizer/dakshini/kn/wiki-filt.train.text.shuf.txt \\\n",
    "#     --data_root=/home/saurabh/manifest/new/kanada_labelled/wpe_50 \\\n",
    "#     --vocab_size=50 \\\n",
    "#     --tokenizer=wpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bpe \n",
    "# ! python3 /home/saurabh/nemo/NeMo/scripts/tokenizers/process_asr_text_tokenizer.py \\\n",
    "#     --manifest=/home/saurabh/manifest/new/kanada_labelled/train.json \\\n",
    "#     --data_root=/home/saurabh/manifest/new/kanada_labelled/spe_1000 \\\n",
    "#     --vocab_size=1000 \\\n",
    "#     --tokenizer=spe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Tokenizer using large corpus\n",
    "# ! python3 /home/saurabh/nemo/NeMo/scripts/tokenizers/process_asr_text_tokenizer.py \\\n",
    "#     --data_file=/home/saurabh/dataset/corpus_data_for_tokenizer/kanada/kn.txt \\\n",
    "#     --data_root=/home/saurabh/manifest/new/kanada_labelled/spe_from_corpus \\\n",
    "#     --vocab_size=32000 \\\n",
    "#     --tokenizer=spe \\\n",
    "#     --spe_train_extremely_large_corpus\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bpe \n",
    "# ! python3 /home/saurabh/nemo/NeMo/scripts/tokenizers/process_asr_text_tokenizer.py \\\n",
    "#     --manifest=/home/saurabh/manifest/new/kanada_labelled/train.json \\\n",
    "#     --data_root=/home/saurabh/manifest/new/kanada_labelled/spe \\\n",
    "#     --vocab_size=100 \\\n",
    "#     --tokenizer=spe\n",
    "\n",
    "# # #wpe    \n",
    "# ! python3 /home/saurabh/nemo/NeMo/scripts/tokenizers/process_asr_text_tokenizer.py \\\n",
    "#     --manifest=/home/saurabh/manifest/new/kanada_labelled/train.json \\\n",
    "#     --data_root=/home/saurabh/manifest/new/kanada_labelled/wpe \\\n",
    "#     --vocab_size=100 \\\n",
    "#     --tokenizer=wpe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import Dependencies ####\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from nemo.utils import exp_manager\n",
    "import pytorch_lightning\n",
    "from omegaconf import OmegaConf, open_dict\n",
    "from nemo.core import adapter_mixins\n",
    "from pytorch_lightning import Trainer\n",
    "from nemo.collections.common.parts.adapter_modules import LinearAdapterConfig\n",
    "import torch\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# Char\n",
    "config_path = '/home/saurabh/nemo/NeMo/examples/asr/conf/conformer/conformer_ctc_char.yaml'\n",
    "params = OmegaConf.load(config_path)\n",
    "params.model.labels = [\"೨\", \"ೇ\", \"ಛ\", \"ಿ\", \"ಞ\", \"ಊ\", \"೧\", \"ಾ\", \"n\", \"'\", \"ಆ\", \"೯\", \"ಉ\", \"ಂ\", \"ಢ\", \"೪\", \"೮\", \"ಲ\", \"ೌ\", \"ಙ\", \"ವ\", \"ಬ\", \"ಧ\", \"ಗ\", \"ೋ\", \"ಳ\", \"ಥ\", \"ಭ\", \"ಚ\", \"೩\", \"ಖ\", \"’\", \"ಓ\", \"ಠ\", \"ಈ\", \"ಕ\", \"ಔ\", \"ು\", \"ಋ\", \"ತ\", \"ಐ\", \"ೀ\", \"ೆ\", \"ಮ\", \"ಘ\", \"೫\", \"ೃ\", \"ೈ\", \"೬\", \"ಷ\", \"ಏ\", \"ದ\", \"ರ\", \"ಇ\", \"್\", \"೭\", \"ಫ\", \"ನ\",\"ೊ\", \"ೂ\", \"ಅ\", \"ಪ\", \"ಝ\", \"ಜ\", \"ಒ\", \"ಯ\", \"ಶ\", \"ಣ\", \"ಟ\", \"ಎ\", \"ಸ\", \"ಹ\", \"ಃ\", \"ಡ\"]\n",
    "\n",
    "\n",
    "# params.model.tokenizer.dir = '/home/saurabh/manifest/new/kanada_labelled/spe_1000/tokenizer_spe_bpe_v1000'\n",
    "# params.model.tokenizer.type = \"bpe\"\n",
    "\n",
    "print(OmegaConf.to_yaml(params))\n",
    "\n",
    "accelerator = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "# accelerator = 'cpu'\n",
    "max_steps = -1\n",
    "max_epochs = 100\n",
    "\n",
    "trainer = Trainer(devices=1, accelerator=accelerator, max_steps=max_steps,\n",
    "                  enable_checkpointing=False, logger=False,\n",
    "                  log_every_n_steps=5, check_val_every_n_epoch=3, \n",
    "                  max_epochs=max_epochs)\n",
    "\n",
    "\n",
    "train_manifest = '/home/saurabh/manifest/new/kanada_labelled/train.json'\n",
    "test_manifest  = '/home/saurabh/manifest/new/kanada_labelled/valid.json' \n",
    "\n",
    "# Update paths to dataset\n",
    "params.model.train_ds.manifest_filepath = train_manifest\n",
    "params.model.validation_ds.manifest_filepath = test_manifest\n",
    "\n",
    "# remove spec augment for this dataset\n",
    "params.model.spec_augment.rect_masks = 0\n",
    "\n",
    "# d_model | n_heads | n_layers | time_masks | lr  |\n",
    "#   176   |    4    |    16    |     5      | 5.0 |\n",
    "\n",
    "# COnformer CTC SMall\n",
    "params.model.spec_augment.time_masks = 10\n",
    "params.model.encoder.d_model = 176\n",
    "params.model.encoder.n_layers = 16\n",
    "params.model.encoder.n_heads = 4\n",
    "# params.optim.lr = 5\n",
    "\n",
    "# OmegaConf.set_struct(params, True)\n",
    "with open_dict(params):\n",
    "    params.model.tokenizer.dir = '/home/saurabh/manifest/new/kanada_labelled'\n",
    "    params.model.tokenizer.type = 'wpe'\n",
    "    \n",
    "exp_direc = '/home/saurabh/experiments/kanada_conformer_wpe'\n",
    "name_exp = 'kanada'\n",
    "#wandb Kargs\n",
    "name_wandb = 'run01'\n",
    "project_wandb = 'kanada'\n",
    "\n",
    "exp_config = exp_manager.ExpManagerConfig(\n",
    "    exp_dir=exp_direc,\n",
    "    name=name_exp,\n",
    "    \n",
    "    checkpoint_callback_params=exp_manager.CallbackParams(\n",
    "        monitor='val_wer',\n",
    "        mode='min',\n",
    "        # always_save_nemo=True,\n",
    "        save_best_model=False,\n",
    "    ),\n",
    "    \n",
    "    resume_if_exists=True,\n",
    "    resume_ignore_no_checkpoint=True,\n",
    "    create_tensorboard_logger= False,\n",
    "    create_checkpoint_callback= True,\n",
    "  \n",
    "    create_wandb_logger=True,\n",
    "    wandb_logger_kwargs={\n",
    "        'name':name_wandb, \n",
    "        'project':project_wandb\n",
    "    },\n",
    ")\n",
    "\n",
    "exp_config=OmegaConf.structured(exp_config)\n",
    "logdir = exp_manager.exp_manager(trainer, exp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.model.optim.lr = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_asr_model = nemo_asr.models.EncDecCTCModelBPE(cfg=params.model, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OmegaConf.to_yaml(first_asr_model.cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(first_asr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## COnformer CTC\n",
    "\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "\n",
    "# !python /home/saurabh/python/nemo/NeMo/examples/asr/asr_ctc/speech_to_text_ctc.py \\\n",
    "# --config-path=/home/saurabh/python/nemo/NeMo/examples/asr/conf/conformer \\\n",
    "# --config-name=conformer_ctc_char \\\n",
    "# model.train_ds.manifest_filepath=/home/saurabh/python/notebooks/nemo_new_18feb/manifest/assamese/train.json \\\n",
    "# model.validation_ds.manifest_filepath=/home/saurabh/python/notebooks/nemo_new_18feb/manifest/assamese/valid.json\\\n",
    "# trainer.max_epochs=4 \\\n",
    "# model.labels=$labels_hindi \\\n",
    "# model.encoder.n_layers=8 \\\n",
    "# model.encoder.n_heads=2\n",
    "\n",
    "# end_time = time.time()\n",
    "# print(f'\\n*** Time: {end_time-start_time} secs***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conformer RNNT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model , load for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "nemo"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
