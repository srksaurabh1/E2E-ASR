{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import Dependencies ####\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from nemo.utils import exp_manager\n",
    "import pytorch_lightning\n",
    "from omegaconf import OmegaConf, open_dict\n",
    "from nemo.core import adapter_mixins\n",
    "from pytorch_lightning import Trainer\n",
    "from nemo.collections.common.parts.adapter_modules import LinearAdapterConfig\n",
    "import torch\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "config_path = '/home/saurabh/nemo/NeMo/examples/asr/conf/wav2vec_ctc/wav2vecCTC.yaml'\n",
    "params = OmegaConf.load(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OmegaConf.to_yaml(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "# accelerator = 'cpu'\n",
    "max_steps = -1\n",
    "max_epochs = 100\n",
    "\n",
    "trainer = Trainer(devices=1, accelerator=accelerator, max_steps=max_steps,\n",
    "                  enable_checkpointing=False, logger=False,\n",
    "                  log_every_n_steps=5, check_val_every_n_epoch=3, \n",
    "                  max_epochs=max_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_manifest = '/home/saurabh/manifest/new/kanada_labelled/train.json'\n",
    "test_manifest  = '/home/saurabh/manifest/new/kanada_labelled/valid.json' \n",
    "\n",
    "# Update paths to dataset\n",
    "params.model.train_ds.manifest_filepath = train_manifest\n",
    "params.model.train_ds.batch_size = 8\n",
    "params.model.validation_ds.manifest_filepath = test_manifest\n",
    "params.model.validation_ds.batch_size = 8\n",
    "params.model.tokenizer.dir = '/home/saurabh/manifest/new/kanada_labelled'\n",
    "params.model.tokenizer.type = 'wpe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OmegaConf.to_yaml(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_direc = '/home/saurabh/experiments/kanada_w2v2_wpe'\n",
    "name_exp = 'kanada'\n",
    "#wandb Kargs\n",
    "name_wandb = 'run01'\n",
    "project_wandb = 'kanada_w2v2'\n",
    "\n",
    "exp_config = exp_manager.ExpManagerConfig(\n",
    "    exp_dir=exp_direc,\n",
    "    name=name_exp,\n",
    "    \n",
    "    checkpoint_callback_params=exp_manager.CallbackParams(\n",
    "        monitor='val_wer',\n",
    "        mode='min',\n",
    "        # always_save_nemo=True,\n",
    "        save_best_model=False,\n",
    "    ),\n",
    "    \n",
    "    resume_if_exists=True,\n",
    "    resume_ignore_no_checkpoint=True,\n",
    "    create_tensorboard_logger= False,\n",
    "    create_checkpoint_callback= True,\n",
    "  \n",
    "    create_wandb_logger=True,\n",
    "    wandb_logger_kwargs={\n",
    "        'name':name_wandb, \n",
    "        'project':project_wandb\n",
    "    },\n",
    ")\n",
    "\n",
    "exp_config=OmegaConf.structured(exp_config)\n",
    "logdir = exp_manager.exp_manager(trainer, exp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  nemo_asr.models.EncDecCTCModelBPE(cfg=params.model, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "nemo"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
